# LLM Key Requestor Configuration

# MCP Server Configuration
mcp:
  # API key for MCP server authentication (can be overridden by MCP_API_KEY env var)
  # IMPORTANT: Change this to a secure random value in production!
  api_key: "change-me-to-a-secure-api-key"

# LiteLLM Backend Configuration
litellm:
  # Base URL for LiteLLM backend (can be overridden by LITELLM_BASE_URL env var)
  base_url: "http://localhost:4000"
  # API key for LiteLLM backend (can be overridden by LITELLM_API_KEY env var)
  api_key: ""
  # Enable fetching models from LiteLLM (can be overridden by ENABLE_LITELLM_MODELS env var)
  enable_litellm_models: true

# Featured Models (Easy Mode) - User-friendly model selection
# These models are displayed prominently with simplified categorization
featured_models:
  - id: "claude-3"
    title: "Model für starke Datensicherheit"
    subtitle: "Anthropic Claude"
    description: "Höchste Sicherheitsstandards und Datenschutz für sensible Anwendungen"
    documentation_link: "https://docs.anthropic.com/claude/docs"
    icon: "simple-icons:anthropic"
    color: "#D4A574"
    
  - id: "openai-gpt4"
    title: "Coding-Modell"
    subtitle: "OpenAI GPT-4"
    description: "Optimiert für Programmierung und technische Aufgaben"
    documentation_link: "https://platform.openai.com/docs"
    icon: "simple-icons:openai"
    color: "#412991"
    
  - id: "gemini-pro"
    title: "Vielseitiges Allround-Modell"
    subtitle: "Google Gemini Pro"
    description: "Flexible Lösung für verschiedene Anwendungsfälle und Aufgaben"
    documentation_link: "https://ai.google.dev/docs"
    icon: "simple-icons:google"
    color: "#4285F4"

# Available LLM Models (Advanced Mode)
# These models are shown in the advanced options section
models:
  - id: "openai-gpt4"
    title: "OpenAI GPT-4"
    icon: "simple-icons:openai"
    color: "#412991"
    description: "Advanced reasoning and complex problem-solving capabilities with extended context window."

  - id: "openai-gpt3.5"
    title: "OpenAI GPT-3.5"
    icon: "simple-icons:openai"
    color: "#412991"
    description: "Fast and efficient model for general-purpose tasks and conversational AI."

  - id: "claude-3"
    title: "Claude 3 (Anthropic)"
    icon: "simple-icons:anthropic"
    color: "#D4A574"
    description: "Anthropic's most capable model with strong reasoning and analysis capabilities."

  - id: "gemini-pro"
    title: "Google Gemini Pro"
    icon: "simple-icons:google"
    color: "#4285F4"
    description: "Google's multimodal AI with excellent performance across text, code, and reasoning tasks."

  - id: "llama-2"
    title: "Meta Llama 2"
    icon: "simple-icons:meta"
    color: "#0866FF"
    description: "Open-source model optimized for dialogue and general-purpose applications."

  - id: "mistral-7b"
    title: "Mistral 7B"
    icon: "simple-icons:mistral"
    color: "#F2A73B"
    description: "Efficient open-weight model with strong performance for its size."

  - id: "grok"
    title: "xAI Grok"
    icon: "mdi:robot"
    color: "#000000"
    description: "xAI's conversational AI with real-time knowledge and unique personality."

  - id: "cohere-command"
    title: "Cohere Command"
    icon: "mdi:message-processing"
    color: "#39594D"
    description: "Enterprise-focused model for text generation and analysis tasks."


# SMTP Configuration
# All settings can be overridden by environment variables:
# SMTP_HOST, SMTP_PORT, SMTP_USER, SMTP_PASSWORD, SMTP_FROM, SMTP_USE_TLS, SMTP_START_TLS
smtp:
  host: "localhost"
  port: 587
  user: ""
  password: ""
  from: "noreply@example.com"
  # use_tls: Use direct TLS connection (typically for port 465)
  use_tls: false
  # start_tls: Use STARTTLS to upgrade connection (typically for port 587)
  start_tls: true

# Approval Queue Configuration
approval:
  # Queue processing interval (can be overridden by APPROVAL_QUEUE_INTERVAL env var)
  # Supported formats: "30s", "1m", "5m", etc.
  queue_interval: "5m"

# Approval Plugins Configuration
# Plugins are dynamically loaded based on configuration and evaluated in sequence.
# Each plugin returns APPROVE, DENY, or CONTINUE.
# If a plugin returns APPROVE or DENY, evaluation stops immediately.
# If all plugins return CONTINUE, the request is denied by default.
approval_plugins:
  # Example configurations (uncomment and configure as needed):
  
  # HTTP Plugin: Query an external HTTP endpoint for approval decisions
  # - name: http
  #   config:
  #     endpoint: "https://example.com/api/approve"

  # Human in the Loop Plugin: Send requests for manual approval via email
  #- name: humanintheloop
  #  config:
  #    email: "bla@example.com"
  #    patterns:
  #      - "claude*"
  
  # Blacklist Plugin: Deny requests matching model patterns
  #- name: blacklist
  #  config:
  #    list:
  #      - "grok/*"

  # Whitelist Plugin: Approve requests matching model patterns
  # - name: whitelist
  #   config:
  #     list:
  #       - "ollama/*"
  #       - "llama-*"
  
  # Email Plugin: Approve/deny based on email pattern
  - name: email
    config:
      pattern: "*@example.com"
